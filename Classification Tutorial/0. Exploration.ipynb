{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "This notebook will explore our dataset to inform our cleaning activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "\n",
    "- ID : the numeric ID of the article\n",
    "- TITLE : the headline of the article\n",
    "- URL : the URL of the article\n",
    "- PUBLISHER : the publisher of the article\n",
    "- CATEGORY : the category of the news item; one of:\n",
    "  - e : entertainment\n",
    "  - b : business\n",
    "  - t : science and technology\n",
    "  - m : health\n",
    "- STORY : alphanumeric ID of the news story that the article discusses\n",
    "- HOSTNAME : hostname where the article was posted\n",
    "- TIMESTAMP : approximate timestamp of the article's publication, given in Unix time (seconds since midnight on Jan 1, 1970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# import seaborn as sns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from src.model_operations import count_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"data/downsampled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the data look like?\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations?\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a typical article title?\n",
    "data['TITLE'][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Column Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any missing values?\n",
    "data['CATEGORY'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of values\n",
    "data['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Column Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any missing values?\n",
    "data['TITLE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of TITLE (number of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has a large impact on our choice of Large Language Model (LLM). \n",
    "\n",
    "LLMs operate on a fixed sequence length.  \n",
    "\n",
    "This means any string shorter than N number of words will be padded to reach a max length.  \n",
    "\n",
    "This max length is set when the LLM is trained.  \n",
    "\n",
    "Further, this is one of the factors that makes different LLMs better at a task than others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check average length of TITLE values\n",
    "data['title length'] = data['TITLE'].apply(count_tokens)\n",
    "\n",
    "\n",
    "# Print out metrics\n",
    "print(f\"Minimum number of words in TITLE: {np.round(data['title length'].min())}\")\n",
    "print(f\"Average number of words in TITLE: {np.round(data['title length'].mean())}\")\n",
    "print(f\"Maximum number of words in TITLE: {np.round(data['title length'].max())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of title length\n",
    "sns.distplot(data['title length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Max values in TITLE\n",
    "high_values = data[data['title length']>10]\n",
    "\n",
    "print(f\"Number of TITLE obs with more than n words: {len(high_values)}\")\n",
    "high_values['TITLE'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Min and Max values in TITLE\n",
    "low_values = data[data['title length']<= 3]\n",
    "\n",
    "# Number of short titles\n",
    "print(f\"Number of TITLE obs with less than n words: {len(low_values)}\")\n",
    "# Check a single value \n",
    "low_values['TITLE'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many observations have special characters?\n",
    "\n",
    "def check_for_special_chars(data):\n",
    "    \"\"\" Checks if a string is comprised entirely of alphanumeric characters. \"\"\"\n",
    "    return data.isalnum()\n",
    "\n",
    "# Check to see if special characters are present\n",
    "data['special chars present'] = data['TITLE'].apply(check_for_special_chars)\n",
    "# Check number of observations with special characters\n",
    "data['special chars present'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how prevalent special chars are in the text\n",
    "def remove_special_chars(data): \n",
    "    \"\"\" Removes special chars from a string. \"\"\"\n",
    "    return re.sub(\"[$&+;=@#|<>^*%-]\",\"\",data)\n",
    "\n",
    "# Remove special characters\n",
    "data['special chars removed'] = data['TITLE'].apply(check_for_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent 50 words\n",
    "\n",
    "#Create DTM\n",
    "cv = CountVectorizer(ngram_range = (1,1))\n",
    "dtm = cv.fit_transform(data['TITLE'])\n",
    "words = np.array(cv.get_feature_names_out())\n",
    "\n",
    "\n",
    "#Look at top 50 most frequent words\n",
    "freqs=dtm.sum(axis=0).A.flatten() \n",
    "index=np.argsort(freqs)[-20:] \n",
    "print(list(zip(words[index], freqs[index])))\n",
    "\n",
    "WordFreq = pd.DataFrame.from_records(list(zip(words[index], freqs[index]))) \n",
    "WordFreq.columns = ['Word', 'Freq']\n",
    "\n",
    "data = dict(zip(WordFreq['Word'].tolist(), WordFreq['Freq'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot horizontal bar graph\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "WordFreq.sort_values(by='Freq').plot.barh(\n",
    "                      x='Word',\n",
    "                      y='Freq',\n",
    "                      ax=ax,\n",
    "                      color=\"deepskyblue\")\n",
    "\n",
    "plt.title(\"Count of Most Common Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
