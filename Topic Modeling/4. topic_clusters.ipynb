{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T16:44:31.696458Z",
     "start_time": "2021-11-05T16:44:24.588768Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Open AI & config\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Visuals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Similarity Search\n",
    "from src.vector_similarity import get_embeddings, execute_similarity_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make connections\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://crrc-t170-cvx-france.openai.azure.com/\"\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "#============#\n",
    "# Data\n",
    "#============#\n",
    "filepath = \"C:\\\\Users\\\\hlmq\\\\OneDrive - Chevron\\\\Desktop\\\\Projects\\\\SETH employee questions\\\\\"\n",
    "\n",
    "# Input\n",
    "filename = \"SETH-questions-summaries.csv\"\n",
    "\n",
    "# Output\n",
    "\n",
    "OUTPUT_DIRNAME = filepath\n",
    "OUTPUT_filename = \"SETH-questions-topicClusters.csv\"\n",
    "\n",
    "\n",
    "keep_columns = ['Question', 'Topic', 'summary']\n",
    "\n",
    "#============#\n",
    "# Model Config\n",
    "#============#\n",
    "k = 24          # Number of clusters to fit (\"topics\")\n",
    "\n",
    "\n",
    "#============#\n",
    "# Open AI prompts\n",
    "#============#\n",
    "cluster_naming_prompt = json.load(open(\"prompts/cluster_naming.json\"))\n",
    "cluster_summary_prompt = json.load(open(\"prompts/cluster_summary.json\"))\n",
    "positive_comment_prompt = json.load(open(\"prompts/positive_comments.json\"))\n",
    "concerns_prompt = json.load(open(\"prompts/concerns.json\"))\n",
    "popular_mentions_prompt = json.load(open(\"prompts/popular_mentions.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-05T16:44:31.806166Z",
     "start_time": "2021-11-05T16:44:31.698454Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Topic</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What leadership behavior changes need to be ma...</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Identifying leadership behavior changes to imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I wanted to ask about unclear messaging coming...</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Employee asks about unclear messaging from Sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the last few years, we have heard an overwh...</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Questioning sudden deviation from positive mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The communication on where we missed and what ...</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Clarity is needed on what actions are necessar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Want to be respectful for sure but I have hear...</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Employees are questioning the effectiveness of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question        Topic  \\\n",
       "0  What leadership behavior changes need to be ma...  Performance   \n",
       "1  I wanted to ask about unclear messaging coming...  Performance   \n",
       "2  In the last few years, we have heard an overwh...  Performance   \n",
       "3  The communication on where we missed and what ...  Performance   \n",
       "4  Want to be respectful for sure but I have hear...  Performance   \n",
       "\n",
       "                                             summary  \n",
       "0  Identifying leadership behavior changes to imp...  \n",
       "1  Employee asks about unclear messaging from Sen...  \n",
       "2  Questioning sudden deviation from positive mes...  \n",
       "3  Clarity is needed on what actions are necessar...  \n",
       "4  Employees are questioning the effectiveness of...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "data = pd.read_csv(str(filepath)+str(filename))\n",
    "\n",
    "# Strip unused columns\n",
    "data = data[keep_columns]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Customer Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings from text\n",
    "embeddings = get_embeddings(data['summary'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=24, random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create cluster algorithm\n",
    "km = KMeans(n_clusters=k, \n",
    "                max_iter=300, \n",
    "                tol=1e-04, \n",
    "                init='k-means++', \n",
    "                n_init=10, \n",
    "                random_state=42, \n",
    "                algorithm='auto')\n",
    "\n",
    "# Fit clusters\n",
    "km.fit(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top observations for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for similarity search\n",
    "\n",
    "# Centroid df\n",
    "cluster_centroids_df = pd.DataFrame()\n",
    "cluster_centroids_df['Cluster Label'] = range(0,k)\n",
    "cluster_centroids_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# Observation df\n",
    "observations_df = pd.DataFrame()\n",
    "observations_df['Cluster Label'] = km.labels_.tolist()\n",
    "observations_df['Question'] = data['Question']\n",
    "observations_df['Topic'] = data['Topic']\n",
    "observations_df['summary'] = data['summary']\n",
    "observations_df.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Search\n",
    "response = execute_similarity_search(3,                                 # How many observations per cluster?                   \n",
    "                                     cluster_centroids_df,              # Cluster DF\n",
    "                                     km.cluster_centers_.tolist(),      # Cluster embeddings\n",
    "                                     observations_df,                   # Observations DF\n",
    "                                     embeddings)                        # Observations embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== #\n",
    "# Summarization -- Open AI API\n",
    "# =========== #\n",
    "\n",
    "def create_summary(data, prompt):\n",
    "    \"\"\" Summarize a customer's comments using the GPT API. \"\"\"\n",
    "    \n",
    "    # Prompt is taken from prompt.json\n",
    "    # Add the customer description to the prompt.\n",
    "    prompt[1]['content'] = ' '.join(data)\n",
    "\n",
    "    try:\n",
    "        # Generate the response from the model\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=\"gpt-35-turbo\",\n",
    "            temperature=1,\n",
    "            messages = prompt,\n",
    "            max_tokens=100,\n",
    "            top_p=0.5,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None\n",
    "            )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION {e}\\nTHROWN FOR {data}\")\n",
    "        return f\"Error : {e}\"\n",
    "\n",
    "\n",
    "# =========== #\n",
    "# Count Observations\n",
    "# =========== #\n",
    "def count_obs(data):\n",
    "    return len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Open AI Summaries\n",
    "\n",
    "# Empty lists to store data\n",
    "overall_original_names = []\n",
    "generated_cluster_names = []\n",
    "overall_counts = []\n",
    "overall_summary = []\n",
    "overall_positive_comments = []\n",
    "overall_concerns = []\n",
    "overall_popular_mentions = []\n",
    "overall_raw_questions = []\n",
    "\n",
    "\n",
    "for i in range(0,k):\n",
    "    # slice on cluster number\n",
    "    check = response[response['Cluster Label']==i]\n",
    "    strings = check['summary'].tolist()\n",
    "    raw_strings = check['Question'].tolist()\n",
    "\n",
    "    # Create summaries\n",
    "    cluster_generated_name = create_summary(strings, cluster_naming_prompt)\n",
    "    cluster_count = count_obs(check)\n",
    "    cluster_summary = create_summary(strings, cluster_summary_prompt)\n",
    "    cluster_positive_comment = create_summary(strings, positive_comment_prompt)\n",
    "    cluster_concerns = create_summary(raw_strings, concerns_prompt)\n",
    "    cluster_popular_mentions = create_summary(strings, popular_mentions_prompt)\n",
    "\n",
    "    # Record summaries\n",
    "    generated_cluster_names.append(cluster_generated_name)\n",
    "    overall_counts.append(cluster_count)\n",
    "    overall_summary.append(cluster_summary)\n",
    "    overall_positive_comments.append(cluster_positive_comment)\n",
    "    overall_concerns.append(cluster_concerns)\n",
    "    overall_popular_mentions.append(cluster_popular_mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add summaries to cluster centroid df\n",
    "cluster_centroids_df['Generated Topic Name'] = generated_cluster_names\n",
    "cluster_centroids_df['Topic Size'] = overall_counts\n",
    "cluster_centroids_df['Topic Summary'] = overall_summary\n",
    "cluster_centroids_df['Positive Comments'] = overall_positive_comments\n",
    "cluster_centroids_df['Concerns'] = overall_concerns\n",
    "cluster_centroids_df['Popular Themes'] = overall_popular_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_centroids_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a join df to remove need to drop columns later.  (Adding cluster results to original observations.)\n",
    "# join_df = pd.DataFrame()\n",
    "# join_df['Cluster Label'] = cluster_centroids_df['Cluster Label']\n",
    "# join_df['Topic Name'] = cluster_centroids_df['6 Word Summary']\n",
    "# print(len(join_df))\n",
    "\n",
    "# Add cluster name to observations dataframe\n",
    "observations_df = pd.merge(observations_df, cluster_centroids_df, on='Cluster Label', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_filepath = \"C:\\\\Users\\\\hlmq\\\\OneDrive - Chevron\\\\Desktop\\\\Projects\\\\SETH employee questions\\\\cluster results\\\\\"\n",
    "\n",
    "# Dataset where I performed semantic search of the top k observations against each cluster centroid.\n",
    "filename_similar_obs = \"Observations Close to Topic Clusters.csv\"\n",
    "\n",
    "# Dataset for time series analysis.  Customer Comments + Cluster Info + Created Date\n",
    "filename_obs_with_cluster_labels = \"Employee Questions with Cluster Labels.csv\"\n",
    "\n",
    "\n",
    "response.to_csv(str(OUTPUT_filepath)+str(filename_similar_obs))\n",
    "observations_df.to_csv(str(OUTPUT_filepath)+str(filename_obs_with_cluster_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if you want to export any data\n",
    "\n",
    "#filepath = 'Models\\\\XGBoost_classifier\\\\out\\\\'\n",
    "#now = datetime.now()\n",
    "#current_time = now.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "#filename_submission = current_time + '_XGBoost_Classifier_Results.csv'\n",
    "#output_data = y_test\n",
    "\n",
    "#output_data.to_csv(filepath+filename_submission, sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Elbow\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "# silhouette_scores = []\n",
    "# for k in range(2, 7):\n",
    "#     km = KMeans(n_clusters=k, \n",
    "#                 max_iter=300, \n",
    "#                 tol=1e-04, \n",
    "#                 init='k-means++', \n",
    "#                 n_init=10, \n",
    "#                 random_state=42, \n",
    "#                 algorithm='auto')\n",
    "#     km.fit(embeddings)\n",
    "#     silhouette_scores.append(silhouette_score(embeddings, km.labels_))\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(range(2, 7), silhouette_scores, 'bx-')\n",
    "# ax.set_title('Silhouette Score Method')\n",
    "# ax.set_xlabel('Number of clusters')\n",
    "# ax.set_ylabel('Silhouette Scores')\n",
    "# plt.xticks(range(2, 7))\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pacmap\\n\\n# PACMAP\\nembedding = pacmap.PaCMAP(random_state=42)\\nX_std_pacmap = embedding.fit_transform(X_std.to_numpy())\\n\\nfor l, c, m in zip(range(0, 3), cluster_colors[0:km_fit.n_clusters], (\\'^\\', \\'s\\', \\'o\\')):\\n    ax2.scatter(X_std_pacmap[y == l, 0],\\n                X_std_pacmap[y == l, 1],\\n                color=c,\\n                label=\\'cluster %s\\' % l,\\n                alpha=0.9,\\n                marker=m\\n                )\\n    \\nax1.set_title(\"PCA Visualization\")\\nax2.set_title(\"PACMAP Visualization\")\\n\\nlabels = np.unique(km_fit.labels_)\\nlabels = [\"cluster \"+str(l) for l in labels]\\nfig.legend(labels, loc=\\'lower center\\',ncol=len(labels), bbox_transform=(1,0),borderaxespad=-0.5)\\nplt.tight_layout()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possibly use for dimensionality reduction\n",
    "\n",
    "\"\"\"\n",
    "import pacmap\n",
    "\n",
    "# PACMAP\n",
    "embedding = pacmap.PaCMAP(random_state=42)\n",
    "X_std_pacmap = embedding.fit_transform(X_std.to_numpy())\n",
    "\n",
    "for l, c, m in zip(range(0, 3), cluster_colors[0:km_fit.n_clusters], ('^', 's', 'o')):\n",
    "    ax2.scatter(X_std_pacmap[y == l, 0],\n",
    "                X_std_pacmap[y == l, 1],\n",
    "                color=c,\n",
    "                label='cluster %s' % l,\n",
    "                alpha=0.9,\n",
    "                marker=m\n",
    "                )\n",
    "    \n",
    "ax1.set_title(\"PCA Visualization\")\n",
    "ax2.set_title(\"PACMAP Visualization\")\n",
    "\n",
    "labels = np.unique(km_fit.labels_)\n",
    "labels = [\"cluster \"+str(l) for l in labels]\n",
    "fig.legend(labels, loc='lower center',ncol=len(labels), bbox_transform=(1,0),borderaxespad=-0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ #\n",
    "#  Slice a df\n",
    "# ============ #\n",
    "\n",
    "# def slice_df_on_topic(data, topic):\n",
    "#     return data[data['Topic__c']==topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PUTS THE STARS BACK ON THE SCATTER PLOT (cluster centroids)\n",
    "\n",
    "# # Centroids\n",
    "# plt.scatter(\n",
    "#         x= cluster_centroids_df['x'], y=cluster_centroids_df['y'],\n",
    "#         c=cluster_centroids_df['Cluster Label'],\n",
    "#         # annot=centroids_df_for_search['6 Word Summary'],\n",
    "#         marker = '*',\n",
    "#         edgecolors='red',\n",
    "#         s=250\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "167.205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
